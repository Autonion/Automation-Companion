<p align="center">
  <h1 align="center">ğŸ¤– Automation Companion</h1>
  <p align="center">
    <b>AI-Powered, On-Device Android Automation â€” No Root, No Cloud, No Limits.</b>
  </p>
  <p align="center">
    <a href="#-features">Features</a> â€¢
    <a href="#%EF%B8%8F-architecture">Architecture</a> â€¢
    <a href="#-getting-started">Getting Started</a> â€¢
    <a href="#-tech-stack">Tech Stack</a> â€¢
    <a href="#-contributing">Contributing</a> â€¢
    <a href="#-license">License</a>
  </p>
  <p align="center">
    <img src="https://img.shields.io/badge/Platform-Android-3DDC84?logo=android&logoColor=white" alt="Platform" />
    <img src="https://img.shields.io/badge/Min%20SDK-24-blue" alt="Min SDK" />
    <img src="https://img.shields.io/badge/Target%20SDK-36-blue" alt="Target SDK" />
    <img src="https://img.shields.io/badge/Language-Kotlin-7F52FF?logo=kotlin&logoColor=white" alt="Kotlin" />
    <img src="https://img.shields.io/badge/UI-Jetpack%20Compose-4285F4?logo=jetpackcompose&logoColor=white" alt="Jetpack Compose" />
    <img src="https://img.shields.io/badge/License-PolyForm%20NC%201.0-orange" alt="License" />
  </p>
</p>

---

## ğŸ“– Overview

**Automation Companion** is an offline-first Android application that empowers users to create powerful automations â€” from simple gesture macros to complex, multi-app workflows â€” entirely on-device. It leverages **Accessibility Services**, **on-device ML (TFLite + ML Kit)**, **screen capture**, and **system event receivers** to automate virtually anything on your phone, without requiring root access or cloud connectivity.

Think of it as **Tasker meets IFTTT meets RPA** â€” built natively for modern Android with Jetpack Compose.

---

## âœ¨ Features

### ğŸ¯ Core Automation

| Feature | Description |
|---------|-------------|
| **ğŸ® Gesture Recording & Playback** | Record taps, swipes, long-presses, scrolls, and text inputs via AccessibilityService and replay them as macros |
| **ğŸ”€ Flow Automation** | Visual node-based workflow editor with drag-to-connect edges, conditional branching, and multi-node execution |
| **ğŸ§  Screen Understanding (ML)** | On-device ML-powered screen analysis â€” OCR text detection, UI element recognition, and image template matching |
| **ğŸ‘ï¸ Visual Triggers** | Configure screen-capture-based triggers that watch for specific visual patterns and execute actions automatically |

### âš¡ System Context Triggers

| Trigger | Description |
|---------|-------------|
| **ğŸ“ Location** | Geofence-based automations with radius, day-of-week, and time-window filtering |
| **ğŸ”‹ Battery** | Trigger actions based on battery level thresholds and charging state |
| **â° Time of Day** | Schedule automations using exact alarms for precise time-based triggers |
| **ğŸ“¶ Wi-Fi** | React to Wi-Fi connect/disconnect events and specific network names |
| **ğŸ“± App Specific** | Per-app automation handlers triggered when specific apps are opened |

### ğŸ› ï¸ Tools & Utilities

| Tool | Description |
|------|-------------|
| **ğŸ› Automation Debugger** | Step-through inspector with categorized logs for every feature module â€” debug your automations in real time |
| **ğŸŒ Cross-Device Automation** | LAN-based multi-device sync (Phone â†” PC â†” Tablet) via local Wi-Fi |
| **ğŸ“¦ Reusable Action System** | Trigger-agnostic actions (SMS, volume, brightness, DnD) shareable across all trigger types |

---

## ğŸ—ï¸ Architecture

The project follows a **multi-layered modular architecture** with strict separation of concerns:

```
app/src/main/java/com/autonion/automationcompanion/
â”œâ”€â”€ ui/                          # Home screen, navigation, theme, shared components
â”œâ”€â”€ core/                        # Interfaces, models, contracts
â”œâ”€â”€ automation/                  # Shared action system (trigger-agnostic)
â”‚   â””â”€â”€ actions/                 # ActionPicker, ActionBuilder, ConfiguredAction
â””â”€â”€ features/                    # Feature modules (isolated)
    â”œâ”€â”€ flow_automation/         # Visual workflow editor + execution engine
    â”‚   â”œâ”€â”€ ui/editor/           # Canvas, ViewModel, node rendering
    â”‚   â”œâ”€â”€ engine/              # FlowExecutionService, node executors
    â”‚   â””â”€â”€ model/               # FlowDefinition, NodeData, Edge
    â”œâ”€â”€ gesture_recording_playback/
    â”‚   â””â”€â”€ overlay/             # OverlayService, AutomationService (Accessibility)
    â”œâ”€â”€ screen_understanding_ml/ # TFLite + ML Kit screen analysis
    â”œâ”€â”€ visual_trigger/          # Vision-based trigger service
    â”œâ”€â”€ system_context_automation/
    â”‚   â”œâ”€â”€ location/            # Geofencing, tracking service, Room DB
    â”‚   â”œâ”€â”€ battery/             # Battery monitoring service
    â”‚   â”œâ”€â”€ timeofday/           # Alarm-based scheduling
    â”‚   â”œâ”€â”€ wifi/                # Wi-Fi state receiver
    â”‚   â””â”€â”€ app_specific/        # Per-app automation handlers
    â”œâ”€â”€ automation_debugger/     # Runtime log inspector
    â”œâ”€â”€ cross_device_automation/ # LAN sync engine
    â””â”€â”€ settings/                # App preferences
```

### Key Design Principles

- **Offline-First** â€” Everything runs on-device, no external servers
- **Modular Features** â€” Each feature is fully isolated with its own UI, engine, and models
- **Trigger-Agnostic Actions** â€” Actions (SMS, volume, brightness, DnD) are decoupled from triggers and reusable everywhere
- **MVVM Pattern** â€” ViewModels manage UI state; clean separation between UI and business logic
- **Accessibility-Powered** â€” Gesture replay and UI inspection via Android AccessibilityService

---

## ğŸš€ Getting Started

### Prerequisites

| Tool | Version |
|------|---------|
| **Android Studio** | Ladybug or later |
| **JDK** | 17 |
| **Gradle** | Wrapper included (`./gradlew`) |
| **Android SDK** | API 24 â€“ 36 |

### Setup

```bash
# Clone the repository
git clone https://github.com/Autonion/Automation-Companion.git
cd Automation-Companion

# Open in Android Studio and let Gradle sync, then Run
# â€” or build via terminal â€”
./gradlew assembleDebug
```

### Required Permissions

The app requests several permissions at runtime for its automation capabilities:

| Permission | Used For |
|------------|----------|
| Accessibility Service | Gesture recording, replay, and UI inspection |
| Overlay (Draw Over Apps) | Floating control panels and recording UI |
| Media Projection | Screen capture for ML analysis and visual triggers |
| Location | Geofence-based automations |
| Exact Alarms | Time-of-day scheduling |
| Notification Access | Posting foreground service notifications |

---

## ğŸ§° Tech Stack

| Layer | Technology |
|-------|------------|
| **Language** | Kotlin |
| **UI Framework** | Jetpack Compose + Material 3 |
| **Navigation** | Compose Navigation |
| **Database** | Room (with KSP) |
| **ML / Vision** | TensorFlow Lite (LiteRT), ML Kit Text Recognition |
| **Native** | C++ via CMake (OpenCV integration) |
| **Networking** | OkHttp (LAN cross-device sync) |
| **Serialization** | Kotlinx Serialization, Gson |
| **Async** | Kotlin Coroutines, WorkManager |
| **Location** | Google Play Services Location, OSMDroid maps |
| **Build System** | Gradle KTS with Version Catalogs |
| **CI/CD** | GitHub Actions |

---

## ğŸ“‚ Documentation

| Document | Description |
|----------|-------------|
| [`docs/PROJECT_OVERVIEW.md`](docs/PROJECT_OVERVIEW.md) | Complete architecture, coding rules, and team workflow |
| [`docs/features.md`](docs/features.md) | Detailed descriptions of every feature module |
| [`docs/getting-started.md`](docs/getting-started.md) | Developer onboarding guide |
| [`ACTIONS_QUICK_REFERENCE.md`](ACTIONS_QUICK_REFERENCE.md) | Quick reference for the shared Actions module |
| [`ARCHITECTURE_REFACTORING.md`](ARCHITECTURE_REFACTORING.md) | Design rationale for the action system refactoring |

---

## ğŸ¤ Contributing

We welcome contributions! Here's how to get started:

1. **Fork** the repository
2. **Create a feature branch** from `develop`:
   ```bash
   git checkout develop
   git checkout -b feature/<feature-name>-<your-name>
   ```
3. **Make your changes** following the [project architecture](docs/PROJECT_OVERVIEW.md)
4. **Open a Pull Request** â†’ `develop` using the [PR template](.github/PULL_REQUEST_TEMPLATE.md)
5. Ensure **CI passes** and get at least **1 reviewer approval**

### Branch Strategy

| Branch | Purpose |
|--------|---------|
| `main` | Stable releases |
| `develop` | Integration branch |
| `feature/*` | Individual feature work |

> âš ï¸ **No direct pushes to `main` or `develop`.**

---

## ğŸ“„ License

This project is licensed under the [**PolyForm Noncommercial License 1.0.0**](LICENSE).

You are free to use, modify, and distribute this software for **noncommercial purposes** â€” personal use, research, education, hobby projects, and more. Commercial use is not permitted under this license.

---

<p align="center">
  Made with â¤ï¸ by the <b>Autonion</b> team
</p>
